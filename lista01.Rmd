---
title: "Lista_01_Econometria_II"
author: "Marcelo Neves Lira"
date: "21076015"
output: pdf_document
---

---

```{r include = FALSE}
# Importando bibliotecas necessárias para resolução dos exercícios

require(wooldridge) # Importando biblioteca com dados do livro
require(tidyverse) # Importando biblitoeca para visualização dos dados
require(faraway) # Importando biblioteca para calcular FIVs
```

## C09 - Capítulo 3

Use the data in CHARITY to answer the following questions:

### 1.Estimate the equation

**gift = b0 + b1mailsyear + b2giftlast + b3propresp + u**

by OLS and report the results in the usual way, including the sample size and R-squared. How does the R-squared compare with that from the simple regression that omits giftlast and propresp?

**Regressão Simples**

``` {r C09.simples}
regressao_c9_i_simples <- lm(gift ~ mailsyear, data = charity)
summary(regressao_c9_i_simples)
```

**Regressão com demais variáveis**

``` {r C09}
regressao_c9_i <- lm(gift ~ mailsyear + giftlast + propresp, data = charity)
summary(regressao_c9_i)
```

<p>**R: Na regressão simples o R² = 0,0138 é inferior ao R² = 0,0834 da regressão com as demais variáveis. Portanto, as variáveis giftlast e propresp ajudam a explicar mais o modelo.**<p>

### 2.Interpret the coefficient on mailsyear. Is it bigger or smaller than the corresponding simple regression coefficient?

<p>**R: Na regressão simples o coeficiente é maior. Isso acontece pois a variável está sendo superestimado**<p>

### 3.Interpret the coefficient on propresp. Be careful to notice the units of measurement of propresp.

<p>**R: Dado que propresp está em proporção, um aumento de 10% em propres, leva ao aumento de 1,54 em gift, mantido outros fatores fixados.**<p>

### 4.Now add the variable avggift to the equation. What happens to the estimated effect of mailsyear?

``` {r c09.iv}
regressao_c9_iv <- lm(gift ~ mailsyear + giftlast + propresp + avggift, data = charity)
summary(regressao_c9_iv)
```

<p>**R: O efeito causado é uma redução no estimador da variável mailsyear**<p>

###5.In the equation from part (iv), what has happened to the coefficient on giftlast? What do you think is happening?

<p>**O efeito causado é a inversão do sinal do estimador de giftlast, ou seja, a quantidade de presente está negativamente relacionada com o presente mais recente.**<p>

---

## C11 - Capítulo 3

<p>Use the data in MEAPSINGLE to study the effects of single-parent households on student math performance. These data are for a subset of schools in southeast Michigan for the year 2000. The socioeconomic variables are obtained at the ZIP code level (where ZIP code is assigned to schools based on their mailing addresses).<p>

### 1.Run the simple regression of math4 on pctsgle and report the results in the usual format. Interpret the slope coefficient. Does the effect of single parenthood seem large or small?

``` {r c11.i}
regressao_c11_i_simples <- lm(math4 ~ pctsgle, data = meapsingle)
summary(regressao_c11_i_simples)
```

<p>**R: O coeficiente é negativamente relacionado com o desempenho em matemética, ou seja, crianças em monoparentalidade performam menos em matemática. O efeito parece ser pequeno.**<p>


### 2.Add the variables lmedinc and free to the equation. What happens to the coefficient on pctsgle? Explain what is happening.

``` {r c11.ii}
regressao_c11_ii <- lm(math4 ~ pctsgle + lmedinc + free, data = meapsingle)
summary(regressao_c11_ii)
```

<p>**R: O coeficiente de pctsgle em módulo ficou menor. Na regressão simples o coeficiente absorvia os efeitos de outras variávies com as quais possuia correlação, superestimando o efeito de pctsgle.**<p>

### 3.Find the sample correlation between lmedinc and free. Does it have the sign you expect?

``` {r c11.iii}
round(cor(meapsingle$lmedinc, meapsingle$free), 2)
```

<p>**R: Correlação entre as variáveis é de -0,75. O resultado da correlação é esperado, pois se espera que famílias que possuem uma renda maior, tenham menos crianças elegíveis à refeições gratuitas**<p>

### 4.Does the substantial correlation between lmedinc and free mean that you should drop one from the regression to better estimate the causal effect of single parenthood on student performance? Explain.

<p>**R: Sim. Matematicamente, correlações altas entre as variáveis independentes causam uma instabilidade numérica ao ajustar a curva de regressão, o chamado efeito de multicolinearidade. Uma das consequências da multicolinearidade é a elevação dos erros-padrão, como observado no erro-padrão do intercepto**<p>

### 5.Find the variance inflation factors (VIFs) for each of the explanatory variables appearing in the regression in part (ii). Which variable has the largest VIF? Does this knowledge affect the model you would use to study the causal effect of single parenthood on math performance?

``` {r c11.v}
dados <- data.frame(
  pctsgle = meapsingle$pctsgle,
  free = meapsingle$free,
  lmedinc = meapsingle$lmedinc
)
vif(dados)
```

<p>**R: pctsgle e lmedinc possuem os maiores FIVs. FIVs maiores que 1 indicam multicolinearidade entre as variáveis.**<p>

---

## C04 - Capítulo 7

### 1.Consider the equation

**colgpa = b0 + b1hsize + b2hsize2 + b3hsperc + b4sat + b5female + b6athlete + u**

where colgpa is cumulative college grade point average; hsize is size of high school graduating class, in hundreds; hsperc is academic percentile in graduating class; sat is combined SAT score; female is a binary gender variable; and athlete is a binary variable, which is one for student athletes. What are your expectations for the coefficients in this equation? Which ones are you unsure about?

<p>**R: B4 > 0, quanto melhor a nota no sat, melhor o desempenho na faculdade. Suponho que B6 < 0, ou seja, atletas performam pior. Os sinais de B1 e B5 não são claros.**<p>

### 2.Estimate the equation in part (i) and report the results in the usual form. What is the estimated GPA differential between athletes and nonathletes? Is it statistically significant?

``` {r C04.ii}
regressao_c04_ii <- lm(colgpa ~ hsize + hsizesq + hsperc + sat + female + athlete, data = gpa2)
summary(regressao_c04_ii)
```

<p>**R: Para atletas o resultado em colgpa é um aumento de 0,169 pontos. O coeficiente é estatísticamente significante.**<p>

### 3.Drop sat from the model and reestimate the equation. Now, what is the estimated effect of being an athlete? Discuss why the estimate is different than that obtained in part (ii).

``` {r C04.iii}
regressao_c04_iii <- lm(colgpa ~ hsize + hsizesq + hsperc + female + athlete, data = gpa2)
summary(regressao_c04_iii)
```

<p>**R: Atletas tem uma previsão de nota maior em 0,0054 pontos, que é praticamente zero. Isso acontece porque não controlamos mais a variável sat.**<p>

### 4.In the model from part (i), allow the effect of being an athlete to differ by gender and test the null hypothesis that there is no ceteris paribus difference between women athletes and women nonathletes.

``` {r C04.iv}
df <- gpa2
df$female_athlete <- gpa2$female & gpa2$athlete
df$male_athlete <- !gpa2$female & gpa2$athlete
df$male_non_athlete <- !gpa2$female & !gpa2$athlete

regressao_c04_iv <- lm(
  colgpa ~ hsize + hsizesq + hsperc + sat +
    female_athlete + male_athlete + male_non_athlete,
  data = df
)
summary(regressao_c04_iv)
```

<p>**R: A nota de mulheres atletas é de 0,175 maior do que mulheres não atletas, mantido outros fatores fixados.**<p>

### 5.Does the effect of sat on colgpa differ by gender? Justify your answer.

``` {r C04.v}

df$female_sat <- gpa2$female * gpa2$sat

regressao_c04_v <- lm(colgpa ~ hsize + hsizesq + hsperc + sat + female + athlete + female_sat, data = df)
summary(regressao_c04_v)
```

<p>**R: O Coeficiente da variável dummy female_sat é 0,0000512 e a estatística t é 0,397. Existe pouca evidência que sat difira por genêro.**<p>

---

## C12 - capítulo 7

<p>Use the data set in BEAUTY, which contains a subset of the variables (but more usable observations than in the regressions) reported by Hamermesh and Biddle (1994).<p>

### 1.Find the separate fractions of men and women that are classified as having above average looks. Are more people rated as having above average or below average looks?

``` {r C12.i}

women_above <- beauty[which(beauty$abvavg & beauty$female), ]
men_above <- beauty[which(beauty$abvavg & !beauty$female), ]
above_avg <- dplyr::bind_rows(women_above, men_above)

women_below <- beauty[which(beauty$belavg & beauty$female), ]
men_below <- beauty[which(beauty$belavg & !beauty$female), ]
below_avg <- dplyr::bind_rows(women_below, men_below)

women_avg <- beauty[which(!beauty$abvavg & !beauty$belavg & beauty$female), ]
men_avg <- beauty[which(!beauty$abvavg & !beauty$belavg & !beauty$female), ]
on_avg <- dplyr::bind_rows(women_avg, men_avg)

total_women <- dplyr::bind_rows(women_above, women_avg, women_below)
total_men <- dplyr::bind_rows(men_above, men_avg, men_below)


fraction_women_above <- round(dplyr::count(women_above)/dplyr::count(total_women), 2)$n
fraction_men_above <- round(dplyr::count(men_above)/dplyr::count(total_men), 2)$n
fraction_women_below <- round(dplyr::count(women_below)/dplyr::count(total_women), 2)$n
fraction_men_below <- round(dplyr::count(men_below)/dplyr::count(total_men), 2)$n

```

* | Mulheres | Homens
:---|:---:|:---:
Acima | 0,33 | 0,29
Abaixo | 0,14 | 0,12

### 2.Test the null hypothesis that the population fractions of above-average-looking women and men are the same. Report the one-sided p-value that the fraction is higher for women. (Hint: Estimating a simple linear probability model is easiest.)<p>

``` {r C12.ii}
regressao_c12_ii <- lm(female ~ abvavg, data = beauty)
summary(regressao_c12_ii)
```

<p>**R: A diferença é de apenas 4%, ou seja, o percentual de mulheres acima da média é um pouco maior do que homens acima da média. A estatística t = 1,48, indica que não existe uma forte evidência de que as populações são as mesmas.**

### 3.Now estimate the model

**log(wage) = b0 + b1belavg + b2abvavg + u**

<p>separately for men and women, and report the results in the usual form. In both cases, interpret the coefficient on belavg. Explain in words what the hypothesis H0: b1 = 0 against H1: b1 ≠ 0 means, and find the p-values for men and women.<p>

``` {r C12.iii}
regressao_c12_men <- lm(lwage ~ belavg + abvavg, data = total_men)
summary(regressao_c12_men)

regressao_c12_women <- lm(lwage ~ belavg + abvavg, data = total_women)
summary(regressao_c12_women)
```

<p>**R: Homens abaixo da média ganham quase 20% menos do que homens na média. Mulheres abaixo da média ganham quase 14% menos do que mulheres na média. No caso dos homens, o coeficiente é bastante significativo (t = |3,314|), portanto existe evidência que a aparência influência no salário. No caso das mulheres não existe uma forte evidência (t = |1,806|) **<p>

### 4.Is there convincing evidence that women with above average looks earn more than women with average looks? Explain.

<p>**R: Dado t = |0,607|, não podemos afirmar que existe forte evidência que mulheres com aparência acima da média ganhem mais que mulheres na média.**<p>

### 5.For both men and women, add the explanatory variables educ, exper, exper2, union, goodhlth, black, married, south, bigcity, smllcity, and service. Do the effects of the “looks” variables change in important ways?

``` {r C12.v}
regressao_c12_men <- lm(lwage ~ belavg + abvavg + educ + exper + expersq 
                        + union + goodhlth + black + married
                        + south + bigcity + smllcity + service, data = total_men)
summary(regressao_c12_men)

regressao_c12_women <- lm(lwage ~ belavg + abvavg + educ + exper + expersq 
                        + union + goodhlth + black + married +
                        south + bigcity + smllcity + service, data = total_women)
summary(regressao_c12_women)

```

<p>**R: Os coeficientes em ambos os casos não se alteram tanto, mesmo com a adição do controle de outras variáveis estatísticamente significantes.**<p>

### 6.Use the SSR form of the Chow F statistic to test whether the slopes of the regression functions in part (v) differ across men and women. Be sure to allow for an intercept shift under the null.